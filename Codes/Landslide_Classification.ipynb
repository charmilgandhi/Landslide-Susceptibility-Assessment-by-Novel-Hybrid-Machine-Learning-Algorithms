{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Landslide_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3n_7-fS0CdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder  # For categorical data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w57PNsHM0Nl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import tools needed for visualization\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.decomposition import PCA\n",
        "import pydot\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "#from pandas_ml import ConfusionMatrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_HjEN6Y0boU",
        "colab_type": "code",
        "outputId": "73e598f4-dc19-4ecd-bd53-989bc93de214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "df = pd.read_csv('Global_Landslide_Final.csv')\n",
        "df.shape # See how many data objects & attributes we have\n",
        "df.head(5) # View first 5 data objects\n",
        "df.landslide_trigger.unique() #See how many unique triggers we have"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Construction', 'Earthquake', 'Flooding', 'Mining', 'Monsoon',\n",
              "       'Rain', 'Snow', 'Tropical_Cyclone'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7ejMf6J9C8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessing by removing noise, replacing NaN\n",
        "# values, replacing NaN/empty values with the median of that attribute and dropping\n",
        "# columns that wouldn't help our model train\n",
        "# Remove unwanted columns\n",
        "df = df.drop(columns=['formatted_date','event_date','event_day','event_title',\n",
        "                      'event_id','event_description','location_description',\n",
        "                      'location_accuracy','gazeteer_closest_point', 'country_code','gazeteer_distance'])\n",
        "df = df.dropna(subset=['landslide_trigger'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu0JOMWP9Omr",
        "colab_type": "code",
        "outputId": "fd02aabe-79bf-4e9b-a645-88b0ab0a2dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Replace NaN values in fatality & injury count with the medians\n",
        "df['fatality_count'].fillna((df['fatality_count'].median()), inplace=True)\n",
        "df['injury_count'].fillna((df['injury_count'].median()), inplace=True)\n",
        "df['population'].fillna((df['population'].median()), inplace=True)\n",
        "df.isnull().sum() # check for missing values in dataset"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "landslide_trigger        0\n",
              "event_month              0\n",
              "event_time             397\n",
              "landslide_category       0\n",
              "landslide_size           0\n",
              "fatality_count           0\n",
              "injury_count             0\n",
              "country_name          1160\n",
              "population               0\n",
              "longitude                0\n",
              "latitude                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-h-Q9hz9UZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete attribute values that we don't want to classify:\n",
        "df = df[df.landslide_size != \"catastrophic\"]\n",
        "df = df[df.landslide_category != \"unknown\"]\n",
        "df = df[df.landslide_category != \"other\"]\n",
        "df = df[df.country_name != \"NaN\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXY4uC7I9X8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update trigger values so reduce unnessessary unique values\n",
        "df['event_time'] = df['event_time'].replace('unknown', 'NaN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qJ_F4Uq9bWD",
        "colab_type": "code",
        "outputId": "cb6379ce-debe-4507-de7f-ff0140272d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Update landlside size values so reduce unnessessary unique values\n",
        "df['landslide_size'] = df['landslide_size'].replace('very_large', 'large')\n",
        "print('Landslide triggers:', df.landslide_trigger.unique())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Landslide triggers: ['Construction' 'Earthquake' 'Flooding' 'Mining' 'Monsoon' 'Rain' 'Snow'\n",
            " 'Tropical_Cyclone']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_LTHolY9fO4",
        "colab_type": "code",
        "outputId": "eb130c91-9fd6-461d-a29f-aebae4ace0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "pd.value_counts(df['landslide_trigger']).plot.bar()\n",
        "plt.title('Landslide Trigger Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Data Objects')\n",
        "df['landslide_trigger'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rain                7964\n",
              "Tropical_Cyclone     562\n",
              "Snow                 133\n",
              "Monsoon              129\n",
              "Mining                93\n",
              "Earthquake            89\n",
              "Construction          86\n",
              "Flooding              74\n",
              "Name: landslide_trigger, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqd0jwRg9jO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['event_time'] = df['event_time'].astype(str)\n",
        "df['landslide_category'] = df['landslide_category'].astype(str) \n",
        "df['country_name'] = df['country_name'].astype(str) #make sure all country name values are strings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkLE909u9n0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.get_dummies(df, prefix=['event_time','country_name','landslide_category','landslide_size'], \n",
        "                    columns=['event_time','country_name','landslide_category','landslide_size'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QV0_W-Q9tEl",
        "colab_type": "code",
        "outputId": "93974e86-05e7-495b-cc2b-37e10c6aebe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Label Encode our trigger values into numbers\n",
        "df[\"landslide_trigger\"] = df[\"landslide_trigger\"].astype('category')\n",
        "df[\"landslide_trigger\"] = df[\"landslide_trigger\"].cat.codes\n",
        "df.head(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>landslide_trigger</th>\n",
              "      <th>event_month</th>\n",
              "      <th>fatality_count</th>\n",
              "      <th>injury_count</th>\n",
              "      <th>population</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>event_time_0:00</th>\n",
              "      <th>event_time_0:30</th>\n",
              "      <th>event_time_10:00</th>\n",
              "      <th>event_time_10:30</th>\n",
              "      <th>event_time_11:00</th>\n",
              "      <th>event_time_11:30</th>\n",
              "      <th>event_time_12:00</th>\n",
              "      <th>event_time_12:30</th>\n",
              "      <th>event_time_13:00</th>\n",
              "      <th>event_time_13:30</th>\n",
              "      <th>event_time_14:00</th>\n",
              "      <th>event_time_14:30</th>\n",
              "      <th>event_time_15:00</th>\n",
              "      <th>event_time_15:30</th>\n",
              "      <th>event_time_16:00</th>\n",
              "      <th>event_time_16:30</th>\n",
              "      <th>event_time_17:00</th>\n",
              "      <th>event_time_17:30</th>\n",
              "      <th>event_time_18:00</th>\n",
              "      <th>event_time_18:30</th>\n",
              "      <th>event_time_19:00</th>\n",
              "      <th>event_time_19:30</th>\n",
              "      <th>event_time_1:00</th>\n",
              "      <th>event_time_1:30</th>\n",
              "      <th>event_time_20:00</th>\n",
              "      <th>event_time_20:30</th>\n",
              "      <th>event_time_21:00</th>\n",
              "      <th>event_time_21:30</th>\n",
              "      <th>event_time_22:00</th>\n",
              "      <th>event_time_22:30</th>\n",
              "      <th>event_time_23:00</th>\n",
              "      <th>event_time_23:30</th>\n",
              "      <th>event_time_2:00</th>\n",
              "      <th>...</th>\n",
              "      <th>country_name_Slovakia</th>\n",
              "      <th>country_name_Slovenia</th>\n",
              "      <th>country_name_Solomon Islands</th>\n",
              "      <th>country_name_South Africa</th>\n",
              "      <th>country_name_South Korea</th>\n",
              "      <th>country_name_Spain</th>\n",
              "      <th>country_name_Sri Lanka</th>\n",
              "      <th>country_name_Sudan</th>\n",
              "      <th>country_name_Swaziland</th>\n",
              "      <th>country_name_Switzerland</th>\n",
              "      <th>country_name_Taiwan</th>\n",
              "      <th>country_name_Tajikistan</th>\n",
              "      <th>country_name_Tanzania</th>\n",
              "      <th>country_name_Thailand</th>\n",
              "      <th>country_name_Trinidad and Tobago</th>\n",
              "      <th>country_name_Turkey</th>\n",
              "      <th>country_name_U.S. Virgin Islands</th>\n",
              "      <th>country_name_Uganda</th>\n",
              "      <th>country_name_Ukraine</th>\n",
              "      <th>country_name_United Arab Emirates</th>\n",
              "      <th>country_name_United Kingdom</th>\n",
              "      <th>country_name_United States</th>\n",
              "      <th>country_name_Vanuatu</th>\n",
              "      <th>country_name_Venezuela</th>\n",
              "      <th>country_name_Vietnam</th>\n",
              "      <th>country_name_Yemen</th>\n",
              "      <th>country_name_nan</th>\n",
              "      <th>landslide_category_complex</th>\n",
              "      <th>landslide_category_creep</th>\n",
              "      <th>landslide_category_debris_flow</th>\n",
              "      <th>landslide_category_earth_fall</th>\n",
              "      <th>landslide_category_earth_flow</th>\n",
              "      <th>landslide_category_lahar</th>\n",
              "      <th>landslide_category_rock_fall</th>\n",
              "      <th>landslide_category_slide</th>\n",
              "      <th>landslide_category_snow_avalanche</th>\n",
              "      <th>landslide_size_large</th>\n",
              "      <th>landslide_size_medium</th>\n",
              "      <th>landslide_size_small</th>\n",
              "      <th>landslide_size_unknown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11886.0</td>\n",
              "      <td>145.1147</td>\n",
              "      <td>-37.8558</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>112050.0</td>\n",
              "      <td>92.7490</td>\n",
              "      <td>11.6753</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>193750.0</td>\n",
              "      <td>28.7701</td>\n",
              "      <td>41.0863</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>601600.0</td>\n",
              "      <td>73.0399</td>\n",
              "      <td>33.6941</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2628.0</td>\n",
              "      <td>44.5015</td>\n",
              "      <td>42.7204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 181 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   landslide_trigger  event_month  ...  landslide_size_small  landslide_size_unknown\n",
              "0                  0            7  ...                     1                       0\n",
              "1                  0            8  ...                     0                       0\n",
              "2                  0            9  ...                     0                       0\n",
              "3                  0            8  ...                     1                       0\n",
              "4                  0            5  ...                     0                       0\n",
              "\n",
              "[5 rows x 181 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTtPZ5A19wJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = np.array(df['landslide_trigger']) \n",
        "df = df.drop('landslide_trigger',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9V4PN2H9zik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the column headers \n",
        "feature_list = list(df.columns)\n",
        "#X = df.as_matrix() # Holds our data objects and attributes\n",
        "X = df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wREG32Kc99dD",
        "colab_type": "code",
        "outputId": "bdc9c4ca-3464-4ef4-d6c2-c0470de69114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Splitting dataset into training and test set\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size =.20)\n",
        "print('Training Features Shape:', train_features.shape)\n",
        "print('Training Labels Shape:', train_labels.shape)\n",
        "print('Testing Features Shape:', test_features.shape)\n",
        "print('Testing Labels Shape:', test_labels.shape)\n",
        "print(\"Before OverSampling, counts of label '0': {}\".format(sum(train_labels==0)))\n",
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(train_labels==1)))\n",
        "print(\"Before OverSampling, counts of label '2': {}\".format(sum(train_labels==2)))\n",
        "print(\"Before OverSampling, counts of label '3': {}\".format(sum(train_labels==3)))\n",
        "print(\"Before OverSampling, counts of label '4': {}\".format(sum(train_labels==4)))\n",
        "print(\"Before OverSampling, counts of label '5': {}\".format(sum(train_labels==5)))\n",
        "print(\"Before OverSampling, counts of label '6': {}\".format(sum(train_labels==6)))\n",
        "print(\"Before OverSampling, counts of label '7': {}\".format(sum(train_labels==7)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Features Shape: (7304, 180)\n",
            "Training Labels Shape: (7304,)\n",
            "Testing Features Shape: (1826, 180)\n",
            "Testing Labels Shape: (1826,)\n",
            "Before OverSampling, counts of label '0': 69\n",
            "Before OverSampling, counts of label '1': 76\n",
            "Before OverSampling, counts of label '2': 62\n",
            "Before OverSampling, counts of label '3': 73\n",
            "Before OverSampling, counts of label '4': 112\n",
            "Before OverSampling, counts of label '5': 6352\n",
            "Before OverSampling, counts of label '6': 99\n",
            "Before OverSampling, counts of label '7': 461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA6P7qiU_bUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm = ADASYN(sampling_strategy='auto')\n",
        "train_features_res, train_labels_res = sm.fit_sample(train_features, train_labels.ravel())\n",
        "sm_svm = SMOTE(kind='svm',sampling_strategy='all')\n",
        "X_smote, Y_smote = sm.fit_sample(train_features, train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfY5Y6P8_kIn",
        "colab_type": "code",
        "outputId": "c2077742-c81e-4a28-df35-ba1b50e377b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "print('After OverSampling, the shape of train_features: {}'.format(train_features_res.shape))\n",
        "print('After OverSampling, the shape of train_labels: {} \\n'.format(train_labels_res.shape))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(train_labels_res==0)))\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(train_labels_res==1)))\n",
        "print(\"After OverSampling, counts of label '2': {}\".format(sum(train_labels_res==2)))\n",
        "print(\"After OverSampling, counts of label '3': {}\".format(sum(train_labels_res==3)))\n",
        "print(\"After OverSampling, counts of label '4': {}\".format(sum(train_labels_res==4)))\n",
        "print(\"After OverSampling, counts of label '5': {}\".format(sum(train_labels_res==5)))\n",
        "print(\"After OverSampling, counts of label '6': {}\".format(sum(train_labels_res==6)))\n",
        "print(\"After OverSampling, counts of label '7': {}\".format(sum(train_labels_res==7)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After OverSampling, the shape of train_features: (50860, 180)\n",
            "After OverSampling, the shape of train_labels: (50860,) \n",
            "\n",
            "After OverSampling, counts of label '0': 6331\n",
            "After OverSampling, counts of label '1': 6336\n",
            "After OverSampling, counts of label '2': 6358\n",
            "After OverSampling, counts of label '3': 6381\n",
            "After OverSampling, counts of label '4': 6341\n",
            "After OverSampling, counts of label '5': 6352\n",
            "After OverSampling, counts of label '6': 6377\n",
            "After OverSampling, counts of label '7': 6384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvYW5sB3_sH2",
        "colab_type": "code",
        "outputId": "156b579e-088c-43c4-a325-4275d3b374b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# GridSearchCV to find the best hyperparameters for our models.\n",
        "\n",
        "tuned_parameters = [{'n_estimators': [100, 200, 500, 1000, 1500], \n",
        "                     'max_features': ['auto', 'sqrt', 'log2'],\n",
        "                     'min_samples_leaf': [50, 75, 100, 150],\n",
        "                     'random_state': [0, 50],\n",
        "                     'class_weight': ['balanced', \n",
        "                                    {0:100, 1:100, 2:100, 3:1000, 4:10, 5:1, 6:10, 7:10},\n",
        "                                    {0:1, 1:1, 2:1, 3:1, 4:1, 5:.01, 6:.1, 7:.1}]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    \n",
        "    clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5,\n",
        "                       scoring='%s_macro' % score)\n",
        "    clf.fit(train_features, train_labels)\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = test_labels, clf.predict(test_features)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.377 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "0.333 (+/-0.043) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "0.371 (+/-0.055) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "0.371 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "0.369 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "0.374 (+/-0.070) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "0.359 (+/-0.039) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.369 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.365 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.360 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.310 (+/-0.139) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "0.338 (+/-0.063) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "0.323 (+/-0.056) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "0.338 (+/-0.095) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "0.324 (+/-0.052) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "0.303 (+/-0.023) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "0.305 (+/-0.070) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.310 (+/-0.066) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.307 (+/-0.079) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.316 (+/-0.069) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.297 (+/-0.084) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "0.356 (+/-0.113) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "0.310 (+/-0.106) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "0.349 (+/-0.073) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "0.315 (+/-0.080) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "0.318 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "0.303 (+/-0.076) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.331 (+/-0.041) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.315 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.321 (+/-0.068) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.171 (+/-0.063) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "0.219 (+/-0.165) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "0.191 (+/-0.111) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "0.298 (+/-0.130) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "0.220 (+/-0.131) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "0.263 (+/-0.187) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "0.218 (+/-0.138) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.232 (+/-0.152) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.225 (+/-0.143) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.227 (+/-0.139) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.377 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "0.333 (+/-0.043) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "0.371 (+/-0.055) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "0.371 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "0.369 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "0.374 (+/-0.070) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "0.359 (+/-0.039) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.369 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.365 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.360 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.310 (+/-0.139) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "0.338 (+/-0.063) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "0.323 (+/-0.056) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "0.338 (+/-0.095) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "0.324 (+/-0.052) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "0.303 (+/-0.023) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "0.305 (+/-0.070) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.310 (+/-0.066) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.307 (+/-0.079) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.316 (+/-0.069) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.297 (+/-0.084) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "0.356 (+/-0.113) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "0.310 (+/-0.106) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "0.349 (+/-0.073) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "0.315 (+/-0.080) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "0.318 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "0.303 (+/-0.076) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.331 (+/-0.041) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.315 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.321 (+/-0.068) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.171 (+/-0.063) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "0.219 (+/-0.165) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "0.191 (+/-0.111) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "0.298 (+/-0.130) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "0.220 (+/-0.131) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "0.263 (+/-0.187) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "0.218 (+/-0.138) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.232 (+/-0.152) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.225 (+/-0.143) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.227 (+/-0.139) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.357 (+/-0.115) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "0.376 (+/-0.076) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "0.348 (+/-0.040) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "0.371 (+/-0.062) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "0.346 (+/-0.072) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "0.360 (+/-0.048) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "0.350 (+/-0.059) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.364 (+/-0.046) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.346 (+/-0.052) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.355 (+/-0.034) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.327 (+/-0.075) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "0.336 (+/-0.060) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "0.300 (+/-0.071) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "0.311 (+/-0.068) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "0.300 (+/-0.102) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "0.305 (+/-0.027) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "0.292 (+/-0.106) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.305 (+/-0.041) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.298 (+/-0.121) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.315 (+/-0.042) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.357 (+/-0.058) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "0.373 (+/-0.081) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "0.314 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "0.325 (+/-0.075) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "0.334 (+/-0.064) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "0.314 (+/-0.043) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "0.325 (+/-0.058) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.319 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.338 (+/-0.055) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.318 (+/-0.060) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.214 (+/-0.174) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "0.225 (+/-0.090) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "0.210 (+/-0.170) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "0.301 (+/-0.132) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "0.239 (+/-0.180) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "0.269 (+/-0.147) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "0.234 (+/-0.154) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.248 (+/-0.118) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.218 (+/-0.069) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.257 (+/-0.129) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.11      0.15        18\n",
            "           1       0.37      0.39      0.38        18\n",
            "           2       0.21      0.70      0.32        10\n",
            "           3       0.16      0.47      0.23        15\n",
            "           4       0.42      0.69      0.52        29\n",
            "           5       0.89      0.37      0.53       110\n",
            "\n",
            "    accuracy                           0.42       200\n",
            "   macro avg       0.38      0.45      0.35       200\n",
            "weighted avg       0.63      0.42      0.45       200\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.431 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "0.381 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "0.421 (+/-0.067) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "0.416 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "0.418 (+/-0.031) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "0.419 (+/-0.033) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "0.421 (+/-0.060) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.420 (+/-0.031) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.422 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.418 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.357 (+/-0.025) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "0.352 (+/-0.053) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "0.373 (+/-0.056) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "0.366 (+/-0.076) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "0.376 (+/-0.034) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "0.345 (+/-0.039) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "0.363 (+/-0.013) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.359 (+/-0.038) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.363 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.368 (+/-0.043) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.370 (+/-0.038) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "0.364 (+/-0.040) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "0.383 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "0.377 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "0.383 (+/-0.011) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "0.361 (+/-0.058) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "0.372 (+/-0.027) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.374 (+/-0.033) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.370 (+/-0.047) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.375 (+/-0.049) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.333 (+/-0.058) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "0.307 (+/-0.063) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "0.347 (+/-0.052) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "0.340 (+/-0.068) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "0.361 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "0.340 (+/-0.078) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "0.351 (+/-0.067) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.351 (+/-0.059) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.342 (+/-0.069) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.353 (+/-0.064) for {'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.431 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "0.381 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "0.421 (+/-0.067) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "0.416 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "0.418 (+/-0.031) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "0.419 (+/-0.033) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "0.421 (+/-0.060) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.420 (+/-0.031) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.422 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.418 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.357 (+/-0.025) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "0.352 (+/-0.053) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "0.373 (+/-0.056) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "0.366 (+/-0.076) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "0.376 (+/-0.034) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "0.345 (+/-0.039) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "0.363 (+/-0.013) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.359 (+/-0.038) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.363 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.368 (+/-0.043) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.370 (+/-0.038) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "0.364 (+/-0.040) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "0.383 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "0.377 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "0.383 (+/-0.011) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "0.361 (+/-0.058) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "0.372 (+/-0.027) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.374 (+/-0.033) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.370 (+/-0.047) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.375 (+/-0.049) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.333 (+/-0.058) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "0.307 (+/-0.063) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "0.347 (+/-0.052) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "0.340 (+/-0.068) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "0.361 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "0.340 (+/-0.078) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "0.351 (+/-0.067) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.351 (+/-0.059) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.342 (+/-0.069) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.353 (+/-0.064) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.418 (+/-0.032) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "0.398 (+/-0.033) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "0.397 (+/-0.077) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "0.413 (+/-0.028) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "0.391 (+/-0.049) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "0.418 (+/-0.031) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "0.402 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.421 (+/-0.029) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.397 (+/-0.048) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.429 (+/-0.045) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.371 (+/-0.042) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "0.345 (+/-0.031) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "0.356 (+/-0.017) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "0.367 (+/-0.054) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "0.360 (+/-0.038) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "0.356 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "0.358 (+/-0.028) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.356 (+/-0.042) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.355 (+/-0.037) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.364 (+/-0.062) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.375 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "0.360 (+/-0.036) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "0.368 (+/-0.046) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "0.369 (+/-0.054) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "0.381 (+/-0.048) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "0.362 (+/-0.057) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "0.377 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.369 (+/-0.033) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.379 (+/-0.064) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.368 (+/-0.036) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "0.346 (+/-0.064) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "0.300 (+/-0.035) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "0.351 (+/-0.042) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "0.339 (+/-0.068) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "0.361 (+/-0.040) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "0.346 (+/-0.051) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "0.351 (+/-0.077) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "0.342 (+/-0.060) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "0.339 (+/-0.072) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "0.340 (+/-0.050) for {'class_weight': 'balanced', 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 100, 1: 100, 2: 100, 3: 1000, 4: 10, 5: 1, 6: 10, 7: 10}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'auto', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 75, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 1500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1000, 'random_state': 50}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 0}\n",
            "nan (+/-nan) for {'class_weight': {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0.01, 6: 0.1, 7: 0.1}, 'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 1500, 'random_state': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.11      0.15        18\n",
            "           1       0.37      0.39      0.38        18\n",
            "           2       0.21      0.70      0.32        10\n",
            "           3       0.16      0.47      0.23        15\n",
            "           4       0.42      0.69      0.52        29\n",
            "           5       0.89      0.37      0.53       110\n",
            "\n",
            "    accuracy                           0.42       200\n",
            "   macro avg       0.38      0.45      0.35       200\n",
            "weighted avg       0.63      0.42      0.45       200\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSZK9_1PBhfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the model training completed for both our random forest and svm classifiers.\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=1500, random_state=50, min_samples_leaf=75,\n",
        "                            class_weight='balanced')\n",
        "# SVM\n",
        "svclassifier = SVC(kernel='rbf', class_weight='balanced', C=1.0, random_state=0, \n",
        "                   decision_function_shape = 'ovo')\n",
        "\n",
        "rf.fit(train_features_res, train_labels_res.ravel());\n",
        "svclassifier.fit(X_smote, Y_smote)  \n",
        "y_pred = svclassifier.predict(test_features) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tos9M0tAI5lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    recall = 100 * recall_score(test_labels, predictions, average='macro')\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    print('Recall = {:0.2f}%.'.format(recall))\n",
        "    return accuracy\n",
        "\n",
        "def model_report(model_predictions):\n",
        "    triggers = [0,1,2,3,4,5,6,7]\n",
        "    print(classification_report(test_labels, model_predictions,\n",
        "                            triggers))\n",
        "    confusionMatrix = confusion_matrix(test_labels, model_predictions)\n",
        "    print(\"Confusion Matrix:\\n%s\" % confusionMatrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3P8NuTsI-V7",
        "colab_type": "code",
        "outputId": "0aeb777d-47a4-498f-9365-c0f9e5b2049e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        }
      },
      "source": [
        "rf_accuracy = evaluate(rf, test_features, test_labels)\n",
        "svm_accuracy = evaluate(svclassifier, test_features, test_labels)\n",
        "print('Improvement of {:0.2f}%.'.format( 100 * (rf_accuracy - svm_accuracy) / svm_accuracy))\n",
        "\n",
        "rf_predictions = rf.predict(test_features)\n",
        "svclassifier_predictions = svclassifier.predict(test_features)\n",
        "\n",
        "model_report(rf_predictions)\n",
        "model_report(svclassifier_predictions)   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance\n",
            "Average Error: 1.0100 degrees.\n",
            "Accuracy = nan%.\n",
            "Recall = 45.95%.\n",
            "Model Performance\n",
            "Average Error: 2.7950 degrees.\n",
            "Accuracy = nan%.\n",
            "Recall = 18.24%.\n",
            "Improvement of nan%.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.20      0.26        20\n",
            "           1       0.38      0.17      0.23        18\n",
            "           2       0.40      0.73      0.52        11\n",
            "           3       0.36      0.20      0.26        20\n",
            "           4       0.47      0.62      0.53        26\n",
            "           5       0.77      0.85      0.81       105\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.62      0.62      0.62       200\n",
            "   macro avg       0.34      0.34      0.33       200\n",
            "weighted avg       0.59      0.62      0.59       200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 4  1  3  3  2  7]\n",
            " [ 0  3  2  1  7  5]\n",
            " [ 0  0  8  0  0  3]\n",
            " [ 3  0  3  4  5  5]\n",
            " [ 0  2  0  1 16  7]\n",
            " [ 4  2  4  2  4 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.10      0.13        20\n",
            "           1       0.10      0.94      0.18        18\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.07      0.05      0.06        20\n",
            "           4       0.00      0.00      0.00        26\n",
            "           5       0.00      0.00      0.00       105\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.10      0.10      0.10       200\n",
            "   macro avg       0.04      0.14      0.05       200\n",
            "weighted avg       0.03      0.10      0.03       200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 2 15  0  3  0  0]\n",
            " [ 0 17  1  0  0  0]\n",
            " [ 1  9  0  1  0  0]\n",
            " [ 0 19  0  1  0  0]\n",
            " [ 2 22  0  2  0  0]\n",
            " [ 6 89  2  8  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqPYiwxKJXFC",
        "colab_type": "code",
        "outputId": "cf56f6b6-3120-4336-df6a-209f9b74afb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tree = rf.estimators_[5]\n",
        "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
        "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
        "graph.write_png('tree_sample.png')\n",
        "\n",
        "def GridSearch_table_plot(grid_clf, param_name,\n",
        "                          num_results=15,\n",
        "                          negative=True,\n",
        "                          graph=True,\n",
        "                          display_all_params=True):\n",
        "\n",
        "    from matplotlib      import pyplot as plt\n",
        "    from IPython.display import display\n",
        "    import pandas as pd\n",
        "\n",
        "    clf = grid_clf.best_estimator_\n",
        "    clf_params = grid_clf.best_params_\n",
        "    if negative:\n",
        "        clf_score = -grid_clf.best_score_\n",
        "    else:\n",
        "        clf_score = grid_clf.best_score_\n",
        "    clf_stdev = grid_clf.cv_results_['std_test_score'][grid_clf.best_index_]\n",
        "    cv_results = grid_clf.cv_results_\n",
        "\n",
        "    print(\"best parameters: {}\".format(clf_params))\n",
        "    print(\"best score:      {:0.5f} (+/-{:0.5f})\".format(clf_score, clf_stdev))\n",
        "    if display_all_params:\n",
        "        import pprint\n",
        "        pprint.pprint(clf.get_params())\n",
        "\n",
        "    scores_df = pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
        "\n",
        "    best_row = scores_df.iloc[0, :]\n",
        "    if negative:\n",
        "        best_mean = -best_row['mean_test_score']\n",
        "    else:\n",
        "        best_mean = best_row['mean_test_score']\n",
        "    best_stdev = best_row['std_test_score']\n",
        "    best_param = best_row['param_' + param_name]\n",
        "\n",
        "    display(pd.DataFrame(cv_results) \\\n",
        "            .sort_values(by='rank_test_score').head(num_results))\n",
        "\n",
        "  \n",
        "    scores_df = scores_df.sort_values(by='param_' + param_name)\n",
        "\n",
        "    if negative:\n",
        "        means = -scores_df['mean_test_score']\n",
        "    else:\n",
        "        means = scores_df['mean_test_score']\n",
        "    stds = scores_df['std_test_score']\n",
        "    params = scores_df['param_' + param_name]\n",
        "\n",
        "   \n",
        "    if graph:\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.errorbar(params, means, yerr=stds)\n",
        "\n",
        "        plt.axhline(y=best_mean + best_stdev, color='red')\n",
        "        plt.axhline(y=best_mean - best_stdev, color='red')\n",
        "        plt.plot(best_param, best_mean, 'or')\n",
        "\n",
        "        plt.title(param_name + \" vs Score\\nBest Score {:0.5f}\".format(clf_score))\n",
        "        plt.xlabel(param_name)\n",
        "        plt.ylabel('Score')\n",
        "        plt.show()\n",
        "\n",
        "grid_clf = GridSearchCV(estimator  = SVC(), \n",
        "                        param_grid = {'C': range(1,10)}, \n",
        "                        cv         = 10)\n",
        "\n",
        "_ = grid_clf.fit(train_features, train_labels)\n",
        "\n",
        "GridSearch_table_plot(grid_clf, \"C\", negative=False)\n",
        "\n",
        "unique_elements, counts_elements = np.unique(train_labels_res, return_counts=True)\n",
        "pd.value_counts(train_labels_res).plot.bar()\n",
        "plt.title('Landslide Trigger Oversampling Data Balance')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters: {'C': 1}\n",
            "best score:      0.52815 (+/-0.00637)\n",
            "{'C': 1,\n",
            " 'break_ties': False,\n",
            " 'cache_size': 200,\n",
            " 'class_weight': None,\n",
            " 'coef0': 0.0,\n",
            " 'decision_function_shape': 'ovr',\n",
            " 'degree': 3,\n",
            " 'gamma': 'scale',\n",
            " 'kernel': 'rbf',\n",
            " 'max_iter': -1,\n",
            " 'probability': False,\n",
            " 'random_state': None,\n",
            " 'shrinking': True,\n",
            " 'tol': 0.001,\n",
            " 'verbose': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_C</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.108790</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.008818</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>1</td>\n",
              "      <td>{'C': 1}</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.528149</td>\n",
              "      <td>0.006370</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.111402</td>\n",
              "      <td>0.003849</td>\n",
              "      <td>0.009031</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>2</td>\n",
              "      <td>{'C': 2}</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.526899</td>\n",
              "      <td>0.005591</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.113042</td>\n",
              "      <td>0.004084</td>\n",
              "      <td>0.008790</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>3</td>\n",
              "      <td>{'C': 3}</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.526899</td>\n",
              "      <td>0.005591</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.115336</td>\n",
              "      <td>0.003905</td>\n",
              "      <td>0.008891</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>4</td>\n",
              "      <td>{'C': 4}</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.525649</td>\n",
              "      <td>0.007076</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.116987</td>\n",
              "      <td>0.006489</td>\n",
              "      <td>0.008920</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>5</td>\n",
              "      <td>{'C': 5}</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.525649</td>\n",
              "      <td>0.007076</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.118078</td>\n",
              "      <td>0.005218</td>\n",
              "      <td>0.008927</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>6</td>\n",
              "      <td>{'C': 6}</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.524399</td>\n",
              "      <td>0.008109</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.120061</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.008920</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>7</td>\n",
              "      <td>{'C': 7}</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.524399</td>\n",
              "      <td>0.008109</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.121816</td>\n",
              "      <td>0.005059</td>\n",
              "      <td>0.008927</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>8</td>\n",
              "      <td>{'C': 8}</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.524399</td>\n",
              "      <td>0.008109</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.121830</td>\n",
              "      <td>0.005279</td>\n",
              "      <td>0.008974</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>9</td>\n",
              "      <td>{'C': 9}</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.524399</td>\n",
              "      <td>0.008109</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0       0.108790      0.003260  ...        0.006370                1\n",
              "1       0.111402      0.003849  ...        0.005591                2\n",
              "2       0.113042      0.004084  ...        0.005591                2\n",
              "3       0.115336      0.003905  ...        0.007076                4\n",
              "4       0.116987      0.006489  ...        0.007076                4\n",
              "5       0.118078      0.005218  ...        0.008109                6\n",
              "6       0.120061      0.005800  ...        0.008109                6\n",
              "7       0.121816      0.005059  ...        0.008109                6\n",
              "8       0.121830      0.005279  ...        0.008109                6\n",
              "\n",
              "[9 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAH/CAYAAAAov8XRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3debxVdb3/8deHAwioiAMqCoqK85AD\noqYCak7lRVNTzCy6DlmSml27WjfrZ3VvTmkOpYQmOWJOoeIcIuWQRyQEFUUcQBwQnAfGz++PvY5t\nT0fPAc5mH855PR+P/XCt71rftT7fo7Xfe42RmUiSpLatXbULkCRJ1WcgkCRJBgJJkmQgkCRJGAgk\nSRIGAkmShIFAkiRhIJDavIj4ekTURsT7EfFqRNwZEbtVeJ8/jogXin3OiIiRldyfpMYZCKQ2LCJO\nAS4A/hdYC1gP+B1wYAX3+S3gKOBLmbkS0Be4v5n30b45tye1BQYCqY2KiFWAM4ETMvPmzPwgM+dn\n5m2ZeWoD6+8UEa9FRE1Z21cjYmIx3a840vBuRLweEb/5jF3vCNydmc8DZOZrmTmsbJurRcQfI2Jm\nRLwVEbeWLTs2IqZGxJyIGBUR65Qty4g4ISKeA54r2g6IiAkR8XZEPBQR2yzVH01qxQwEUtu1C9AJ\nuKUpK2fmo8AHwJ5lzV8Hri2mfwv8NjO7AhsBN3zGph4BvhkRp0ZE3/KAUbgK6AJsCawJnA8QEXsC\n/wccBvQAXgKur9f3IGAnYIuI2A64AvgOsDpwGTAqIlZoyniltsZAILVdqwNvZuaCxehzHXAEQESs\nDHy5aAOYD/SJiDUy8/3MfKShDWTm1cD3gX2BscAbEfHfxTZ7APsDx2fmW8URi7FF1yOBKzJzfGbO\nBU4HdomI3mWb/7/MnJOZHwHHAZdl5qOZuTAzRwBzgZ0XY7xSm2EgkNqu2cAai3m+/Vrg4OJX9sHA\n+Mx8qVh2NLAJ8ExEPBYRB3zWRjLzmsz8EtANOB74RUTsC/QC5mTmWw10W4fSUYG6bbxfjGHdsnWm\nl02vD/ywOF3wdkS8XWx/HST9GwOB1HY9TOkX80FN7ZCZT1H6Ut6fT58uIDOfy8wjKB3mPwu4MSJW\nbGR78zPzz8BEYCtKX+irRUS3BlafSelLHoBi26sDr5Rvsmx6OvCrzOxW9umSmdch6d8YCKQ2KjPf\nAc4ALomIgyKiS0R0iIj9I+Lsz+l6LXAS0B/4c11jRHwjIrpn5iLg7aJ5Uf3OETEkIr4SEStHRLuI\n2J/S9QKPZuarwJ3A7yJi1aKe/kXX64BvR8S2xRGK/y36vPgZdf4BOL64GDIiYsW6/TbxTyS1KQYC\nqQ3LzPOAU4D/AWZR+lU9FLj1c7pdBwwA/pqZb5a17wdMjoj3KV1gOLg4l1/fu8CPgZcpBYezge9m\n5t+K5UdRuh7hGeAN4OSi1vuAnwI3Aa9SunBx8OeMrRY4FrgYeAuYCgz5nHFJbVpkZuNrSZKkVs0j\nBJIkyUAgSZIMBJIkCQOBJEnCQCBJkjAQSC1ORLwYER8VrwZ+KyLuiIhezbTdLzWyTot7LXFE9I6I\nMRHxYUQ883ljiIgrI2JeUX/dp6ZYtnNE3Fu8GGlWRPy5eFRyXd8VIuLS4sVMcyLitohYt2z50OLl\nTXMj4soGasx6+/1pBf4cUsUYCKSW6T+KVwP3AF4HLqr0Dlvwa4mvA56g9FTCn1B6AmL3z1n/7Mxc\nqeyzsGhfFRgG9Kb0xMP3gD+W9TuJ0guftqH0eOO3+PTffSbwS0ovTPos3cr2+4umDlBqCQwEUguW\nmR8DNwJb1LUVv2TPjYiXi1+zl0ZE52LZGhFxe/Hs/jkRMa54GuBVwHrAbcWv1x81sLsW91riiNgE\n2B74WWZ+lJk3AU8ChyzB3/LOzPxzZr6bmR9SemDRrmWrbFCM//Xi7z6S0hMU6/rfnJm3Unp/gtTq\nGAikFiwiugCHU3plcJ1fU3qJ0LZAH0ov9zmjWPZDYAbQHViL0hMBMzOPovRkwP8ofr029Gjilvha\n4i2BaZn5XlnbPyn7om7A94pg8nhEfF5w6A9MLpu/HNg1ItYp/u5HUnqM8uJ4qTjV8seIWGMx+0pV\nZSCQWqZbo/R2vneAvYFzACIiKL3W9wfFa37fo/RM/7pH+M6n9KW8fvHioHHZxMeRttDXEq9U/A3K\nvQN81vsILgQ2phRYfgpcGRG71l+pOCJxBnBqWfNzlB7d/AqlxytvDpz5Gfup701KR1jWB3Yo6rum\niX2lFsFAILVMB2VmN6ATpXcLjI2ItSn98u8CPB7/eqXvXUU7lILDVOCeiJgWEactzk5b4GuJ3we6\n1mvrSun8f0P1j8/M2Zm5IDNHU/pSPrh8nYjoQ+mX/0mZOa5s0SXACpSOWqwI3EwTjxBk5vuZWVvs\n93VK/8728UVKWp4YCKQWrPgFfTOwENiN0i/Rj4Aty17pu0pxESCZ+V5m/jAzNwQGAadExF51m1uM\n/baU1xJPBjas98X6BT59qP9zhwJEWW3rA/cBv8jMq+qtuy1wZXEkYy6lCwr7LeGh/7rx+v+xWm74\nH6vUgkXJgZSukH+6eLXwH4DzI2LNYp11i1/xdRfr9SlOLbxDKUjUvYL4dWDDz9lXi3stcWY+C0wA\nfhYRnSLiq5TuArjpM8ZwaESsVNS/D/ANYFTd3wn4K3BxZl7aQPfHKF1DsUpEdAC+B8yse6NjRLSP\niE5ADVBT1NO+WLZTRGxa7Hd1SqcuHiheMS0tHzLTjx8/LegDvEjpKMD7lA6NTwKOLFveidKX7jRK\n57qfBk4slv2g6P8BpYsLf1rW70D+9crh/2pgvwcDf6d0u927lK7mH1K2fDVgBKVg8RZwc9my44Hn\ngTnA7UDPsmUJ9Km3r/0ofQG/TelVxn8GVv6Mv0dv4IHibzKF0m2RdcuOBCaXzY+jFITepXTx4eCy\nZT8ranm//FO2fHVKpxjeKOr6G9CvbPnPi/7ln58Xy44AXij+7q8CfwLWrvZ/S378LM7H1x9LkiRP\nGUiSJAOBJEnCQCBJkjAQSJIkDASSJAlYkjePtRprrLFG9u7du9plSJK0zDz++ONvZua/vTG0TQeC\n3r17U1tbW+0yJElaZiLipYbaPWUgSZIMBJIkyUAgSZIwEEiSJCocCCJiv4iYEhFTG3ove/F2tVkR\nMaH4HFO0rx8R44u2yRFxfFmfB4pt1vWpe+PbChExstjXoxHRu5JjkySpNanYXQYRUQNcAuxN6a1r\nj0XEqMx8qt6qIzNzaL22V4FdMnNuRKwETCr6ziyWH5mZ9W8POBp4KzP7RMRg4Czg8GYdlCRJrVQl\njxD0A6Zm5rTMnAdcT+n1q43KzHmZObeYXYGm1XkgpVezAtwI7FW8E16SJDWikoFgXWB62fyMoq2+\nQyJiYkTcGBG96hojoldETCy2cVbZ0QGAPxanC35a9qX/yf4ycwGld6KvXn9nEXFcRNRGRO2sWbOW\naoCSJLUW1b6o8Dagd2ZuA9zLv37hk5nTi/Y+wLciYq1i0ZGZuTWwe/E5anF2mJnDMrNvZvbt3v3f\nHtQkSVKbVMlA8ArQq2y+Z9H2icycXXZqYDiwQ/2NFEcGJlH68iczXyn++R5wLaVTE5/aX0S0B1YB\nZjfTWCRJatUqGQgeAzaOiA0ioiMwGBhVvkJE9CibHQQ8XbT3jIjOxfSqwG7AlIhoHxFrFO0dgAMo\nhQWKbX+rmD4U+GtmZkVGJklSK1Oxuwwyc0FEDAXuBmqAKzJzckScCdRm5ijgxIgYBCwA5gBDiu6b\nA+dFRAIBnJuZT0bEisDdRRioAe4D/lD0uRy4KiKmFtsaXKmxSZLU2kRb/hHdt2/f9OVGkqS2JCIe\nz8y+9durfVGhJElqAQwEkiTJQCBJkgwEkiSJCt5lsFyYMgUGDqx2FZIkVZ1HCJrJ5JnvMnnmu9Uu\nQ5KkJdK2jxBsuik88ECzbOrMyx4GYOR3dmmW7UmSVBGf8d4/jxBIkiQDgSRJMhBIkiQMBJIkCQOB\nJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOB\nJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOB\nJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIC03Dr/sYQ6/7OFql7HU\nWss4pNamooEgIvaLiCkRMTUiTmtg+ZCImBURE4rPMUX7+hExvmibHBHHF+1dIuKOiHimaP91Y9uS\nJEmNa1+pDUdEDXAJsDcwA3gsIkZl5lP1Vh2ZmUPrtb0K7JKZcyNiJWBSRIwC3gbOzcwxEdERuD8i\n9s/MOz9nW5IkqRGVPELQD5iamdMycx5wPXBgUzpm5rzMnFvMrkBRZ2Z+mJlj6tYBxgM9m71ySZLa\nmEoGgnWB6WXzM4q2+g6JiIkRcWNE9KprjIheETGx2MZZmTmzvFNEdAP+A7i/sW3V63dcRNRGRO2s\nWbOWcGiS1Lquh3AsLc+yHke1Lyq8DeidmdsA9wIj6hZk5vSivQ/wrYhYq25ZRLQHrgMuzMxpjW2r\nXGYOy8y+mdm3e/fuFRnU8q61/I8JWtdYJKmSKhkIXgHKf6X3LNo+kZmzy04NDAd2qL+R4sjAJGD3\nsuZhwHOZecHibEuSJDWskoHgMWDjiNiguABwMDCqfIWI6FE2Owh4umjvGRGdi+lVgd2AKcX8L4FV\ngJObsi1JktS4it1lkJkLImIocDdQA1yRmZMj4kygNjNHASdGxCBgATAHGFJ03xw4LyISCEp3FjwZ\nET2BnwDPAOMjAuDizBz+OduSJEmNqFggAMjM0cDoem1nlE2fDpzeQL97gW0aaJ9BKSA0tK8GtyVJ\nkhpX7YsKJUlSC2AgkCRJBgJJkmQgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIk\nYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIk\nYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIk\nYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSFQ4EEbFfREyJ\niKkRcVoDy4dExKyImFB8jina14+I8UXb5Ig4vqzPDhHxZLHNCyMiivbVIuLeiHiu+OeqlRybJEmt\nScUCQUTUAJcA+wNbAEdExBYNrDoyM7ctPsOLtleBXTJzW2An4LSIWKdY9nvgWGDj4rNf0X4acH9m\nbgzcX8xLkqQmqOQRgn7A1MyclpnzgOuBA5vSMTPnZebcYnYFijojogfQNTMfycwE/gQcVKx3IDCi\nmB5R1i5JkhpRyUCwLjC9bH5G0VbfIRExMSJujIhedY0R0SsiJhbbOCszZxb9Z3zGNtfKzFeL6deA\ntZppHJIktXrVvqjwNqB3Zm4D3Mu/fuGTmdOL9j7AtyKiyV/wxdGDbGhZRBwXEbURUTtr1qylq16S\npFaikoHgFaBX2XzPou0TmTm77NTAcGCH+hspjgxMAnYv+vf8jG2+XpxSqDu18EZDRWXmsMzsm5l9\nu3fvvtiDkiSpNapkIHgM2DgiNoiIjsBgYFT5CnVf4IVBwNNFe8+I6FxMrwrsBkwpTgm8GxE7F3cX\nfBP4S9F/FPCtYvpbZe2SJKkR7Su14cxcEBFDgbuBGuCKzJwcEWcCtZk5CjgxIgYBC4A5wJCi++bA\neRGRQADnZuaTxbLvAVcCnYE7iw/Ar4EbIuJo4CXgsEqNTZKk1qZigQAgM0cDo+u1nVE2fTpwegP9\n7gW2+Yxt1gJbNdA+G9hrKUuWJKlNqvZFhZIkqQUwEEiSJAOBJEkyEEiSJAwEkiQJA4EkScJAIEmS\nMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmS\nMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmS\nMBBIkiQMBM3jmmu4+Mdf5brjd4XeveGaa6pdkSRJi6V9tQtY7l1zDRx3HN0//JCP2q9A55deguOO\nKy078sjq1iZJUhN5hGBp/eQn8OGHTFpzQ3Y6YQSX7Pw1Ppy/sNQuSdJywkCwtF5+GYAV539Mv+mT\nOGfAtxhw3B+4erUtmL9wUZWLkySpaQwES2u99QDY4K2ZDL/5l9x49an0futV/mefE9jn/Ae5feJM\nFi3KKhcpSdLnMxAsrV/9Crp0+WS27ytPc8Ot/4/L13+fjjXtGHrtExx4yd8Z99ysKhYpSdLnMxAs\nrSOPhGHDmLXaWiwiYP31iWHD2Ou7hzP6pN35zWFfYM4H8zjq8n9w5PBHmDjj7WpXLEnSv/Eug+Zw\n5JEMfX9DAEZ+Z5dPmmvaBQdv35OvbNODax55mYvHTGXQxX/nK1v34If7bMKG3VeqVsWSJH2KRwiW\ngRXa1/Cfu23A2FMHcuJeGzNmyhvsff6DnH7zk7z+7sfVLk+SJAPBsrRypw6csvcmjD11D47aeX1u\nfHw6A84Zw1l3PcM7H82vdnmSpDbMQFAF3VdegZ8P2pL7TxnIfluuzaVjn6f/2WO4bOzzfDx/YbXL\nkyS1QQaCKlpv9S5cMHg77vj+7my3Xjf+785nGHjOA1z/j5dZ4DMMJEnLkIGgBdhina5c+e1+XH/c\nzvTo1onTbn6SfS94kLsmvUqmzzCQJFVeRQNBROwXEVMiYmpEnNbA8iERMSsiJhSfY4r2bSPi4YiY\nHBETI+Lwsj7jytafGRG3Fu0DI+KdsmVnVHJslbDzhqtz83e/yGVH7UBEcPzV4znodw/x0PNvVrs0\nSVIrV7HbDiOiBrgE2BuYATwWEaMy86l6q47MzKH12j4EvpmZz0XEOsDjEXF3Zr6dmbuX7eMm4C9l\n/cZl5gHNP5plJyLYd8u12WuzNbl5/Cucf9+zfP0Pj9J/k+78aN9N2WrdVapdoiSpFarkEYJ+wNTM\nnJaZ84DrgQOb0jEzn83M54rpmcAbQPfydSKiK7AncGuzVt1CtK9px2E79mLMfw3kJ1/enIkz3uaA\ni/7Gidc9wUuzP6h2eZKkVqaSgWBdYHrZ/Iyirb5DitMCN0ZEr/oLI6If0BF4vt6ig4D7M/PdsrZd\nIuKfEXFnRGy5lPW3CJ061HBs/w0Ze+oenLDHRtzz1Gvsdd5YzvjLJN54z2cYSJKaR7UvKrwN6J2Z\n2wD3AiPKF0ZED+Aq4NuZWf+y+yOA68rmxwPrZ+YXgIv4jCMHEXFcRNRGRO2sWcvP+wVW6dyBU/fd\njAdP3YPDd+zFNY++zMBzHuC8e6bw3sc+w0CStHQqGQheAcp/8fcs2j6RmbMzc24xOxzYoW5ZcUrg\nDuAnmflIeb+IWIPSKYk7yrb1bma+X0yPBjoU631KZg7LzL6Z2bd79+71F7d4a3btxK++ujX3nTKA\nPTdbk4v+OpX+Z49h+LhpPsNAkrTEKhkIHgM2jogNIqIjMBgYVb5CcQSgziDg6aK9I3AL8KfMvLGB\nbR8K3J6Znxwzj4i1IyKK6X6Uxja7GcfTomywxopc/PXtuW3obmy17ir88o6n2eu8sfy5djoLfd2y\nJGkxVSwQZOYCYChwN6Uv+hsyc3JEnBkRg4rVTixuLfwncCIwpGg/DOgPDCm7jXDbss0P5tOnC6AU\nEiYV27oQGJxt4Cb+rXuuwlVH78Q1x+zE6it15NQbJ7L/bx/k3qde9xkGkqQmq+jbDotD96PrtZ1R\nNn06cHoD/a4Grv6c7Q5soO1i4OKlKHe5tmufNfjLCbty56TXOPfuKRz7p1r6rr8q/73/ZuzYe7Vq\nlydJauGqfVGhmlFE8OWte3D3D/rzv1/dmpfnfMjXLn2Yo698jGdee7fxDUiS2iwDQSvUoaYdX99p\nPcaeugc/2m9T/vHiHPb/7ThOGTmB6XM+rHZ5kqQWyEDQinXuWMP3BvZh3I/24Lj+G3LHk6+y13lj\n+X+3TWb2+3Mb34Akqc0wELQB3bp05PT9N+eBUwdy8PbrMuKhF+l/9hguuO9Z3p+7oNrlSZJaAANB\nG9Jjlc78+pBtuOcHA9h94+5ccN9zDDh7DFf+/QXmLfB1y5LUlhkI2qA+a67EpUftwK0n7Moma63M\nz297ir1+8wC3PvEKi3yGgSS1SQaCNmzbXt249tidGPGf/Vh5hQ6cPHICX75wHG9/OM9nGEhSG1PR\n5xCo5YsIBmzSnd37rMFtE2dy3j3P8vKcD+nUoR0HXDSu2uUttWmzPmClFdoz8+2PWKdb52qXI0kt\nloFAALRrFxy47brsv1UP9jl/LG9/NJ+1Vu5U7bKW2vQ5HzHrvbkMPPcBhnyxN98buBHdunSsdlmS\n1OIYCPQpHdu3Y62unViraycuH7JjtctZaodf9jBz5y9kwzVX4g/jpnHdP17m+AEb8Z+7bkDnjjXV\nLk+SWgyvIVCrt0KHGn5z2LbcedLu9Ou9GufcPYUB54zh6kdeYv5C766QJDAQqA3ZbO2uXD5kR/58\n/C70Wq0L/3PrJPY5/0FunzjTuysktXkGArU5O/ZejRuP34Xh3+xLh5pg6LVPcOAlf+dvz71Z7dIk\nqWoMBGqTIoIvbbEWd57Un3O/9gXmfDCPb1z+KN8Y/igTZ7xd7fIkaZkzEKhNq2kXHLpDT+7/4QD+\n5yubM3nmOwy6+O+ccM14ps16v9rlSdIyYyCQgE4dajhm9w158Ed7cOKefRgz5Q32Pv9BfnzLk7z+\n7sfVLk+SKs5AIJVZuVMHTtlnU8aeugdH7rQeNzw2nQHnjOHsu57hnY/mV7s8SaoYA4HUgO4rr8CZ\nB27F/T8cwD5brM3vHnie/mePYdiDz/Px/IXVLk+Smp2BQPoc66++IhcesR13nLgb2/bqxv+OfoY9\nzn2AkY+9zAKfYSCpFTEQSE2w5TqrMOI/+3HdsTuzZtdO/PdNT7Lfb8dx16TXfBGUpFbBQCAthl02\nWp1bv/dFLv3G9izK5PirH+fg3z/EI9NmV7s0SVoqBgJpMUUE+23Vg3tO7s9Zh2zNq29/zOBhj/Ct\nK/7B5JnvVLs8SVoiBgJpCbWvacfhO67HA6cO5PT9N2PC9Lf5yoV/46Trn+Dl2R9WuzxJWiwGAmkp\ndepQw3cGbMSDP9qD7w3ciLsnv8Zev3mAn/1lErPem1vt8iSpSQwEUjNZpXMHfrTfZow9dQ++1rcX\nVz/6MgPOGcNv7pnCex/7DANJLZuBQGpma3XtxP9+dWvu/UF/9thsTS7861QGnPMAl//tBeYu8BkG\nklomA4FUIRt2X4lLvr49o4buyhY9uvKL259iz3PHctPjM1jo65YltTAGAqnCtunZjauP2Ymrj96J\n1VbsyA///E++/Ntx3PfU6z7DQFKLYSCQlpHdNl6Dv5ywK5d8fXvmLVzEMX+q5WuXPkzti3OqXZok\nNT0QRETniNi0ksVIrV27dsFXtunBPT/oz6++uhUvz/mQQy99mGNGPMaU196rdnmS2rAmBYKI+A9g\nAnBXMb9tRIyqZGFSa9ahph1H7rQ+Y0/dg1P33ZRHX5jDfr99kFNumMCMt3yGgaRlr6lHCH4O9APe\nBsjMCcAGFapJajM6d6zhhD36MO5He3Dc7hty+8RX2fPcsZx521PM+WBetcuT1IY0NRDMz8z6z2T1\naiipmXTr0pHTv7w5Y08dyFe3W5crH3qB/meP4cL7n+ODuQuqXZ6kNqCpgWByRHwdqImIjSPiIuCh\nCtYltUk9VunMWYduwz0/6M+ufVbnN/c+y4BzxjDioRdZ5B0JkiqofRPX+z7wE2AucC1wN/DLShUl\ntXV91lyZy47qyxMvv8VZdz3Dz0ZNZoX27ejcsYZjRtRWu7ylMuX196iJ4ImX32K79VatdjmSCo0G\ngoioAe7IzD0ohQJJy8h2663KdcfuzNhnZ3HidU8wb8EiZr79UbXLWirzFixi3oJFfPV3D7Hflmvz\nX/tuSp81V6p2WVKb12ggyMyFEbEoIlZp4DoCSRUWEQzcdE0279EVgJHf2aXKFS2dwy97mIWLkl37\nrMHwcdO456nXOKxvL07+0iasvUqnapcntVlNPWXwPvBkRNwLfFDXmJknVqQqSa1aTbvgB3tvwlG7\nrM/Ff53KNY++xC1PvMKQXXvzvQF9WKVLh2qXKLU5TQ0ENxcfSWo2a6y0Aj8ftCVH77YBv7n3WYY9\nOI3rHn2Z4wduxLe/uAGdO9ZUu0SpzWhSIMjMERHREdikaJqSmb7PVVKz6LVaF84/fFuO678hZ9/1\nDGffNYURD73ISXttwmF9e9K+xqesS5XW1CcVDgSeAy4Bfgc8GxH9K1iXpDZo8x5d+eO3+zHyuJ1Z\nt1tnfnzLk+xz/oOMfvJVXwQlVVhTY/d5wD6ZOSAz+wP7AudXrixJbdlOG67OTd/9IsOO2oGadsH3\nrhnPgZf8nb9PfbPapUmtVlMDQYfMnFI3k5nPAl71I6liIoJ9tlybu07uzzmHbsOb783lyOGPctTl\njzLpFW94kppbUwNBbUQMj4iBxecPwPL9dBRJy4WadsHX+vbir/81kP/5yuY8+co7HHDR3xh67Xhe\nfPODxjcgqUmaepfBd4ETgLrbDMdRupZAkpaJTh1qOGb3DTlsx1784cFpDB/3AndNeo3Dd+zFSXtt\nzJpdfYaBtDSaeoSgPfDbzDw4Mw8GLgQavR8oIvaLiCkRMTUiTmtg+ZCImBURE4rPMUX7thHxcERM\njoiJEXF4WZ8rI+KFsj7bFu0RERcW+5oYEds3cWySliNdO3Xgh/tsytgfDeSIfusx8rHpDDjnAc65\n+xne/dibn6Ql1dRAcD/QuWy+M3Df53UoHnl8CbA/sAVwRERs0cCqIzNz2+IzvGj7EPhmZm4J7Adc\nEBHdyvqcWtZnQtG2P7Bx8TkO+H0TxyZpObTmyp34xUFbcd8pA/jSFmtxyZjn6X/2GP7w4DQ+nr+w\n2uVJy52mBoJOmfl+3Uwx3dYQLwIAABPbSURBVKWRPv2AqZk5LTPnAdcDBzZlZ5n5bGY+V0zPBN4A\nujfS7UDgT1nyCNAtIno0ZX+Sll+911iRi47Yjtu/vxvb9OzGr0Y/zR7nPsANj01nwcJF1S5PWm40\nNRB8UH4IPiL6Ao29YWVdYHrZ/Iyirb5DikP8N0ZEr/oLI6If0BF4vqz5V0Wf8yNihcXcn6RWaKt1\nV+FP/9mPa4/diTW7duJHN01kv9+O4+7Jr/kMA6kJmhoITgb+HBHjImIcpV/7Q5th/7cBvTNzG+Be\nYET5wuIX/lXAtzOzLuqfDmwG7AisBvz34uwwIo6LiNqIqJ01a9bS1i+phfniRmtw6/e+yO+P3J5F\nmXznqsc55PcP8ei02dUuTWrRPjcQRMSOEbF2Zj5G6Ut4JDAfuAt4oZFtvwKU/+LvWbR9IjNnZ+bc\nYnY4sEPZvrsCdwA/KU4B1PV5tTgtMBf4I6VTE03aX9F/WGb2zcy+3bs3dhZC0vIoIth/6x7cc3J/\nfn3w1sx8+2MOH/YIQ/74D56a+W61y5NapMaOEFwGzCumdwF+TOlCwbeAYY30fQzYOCI2KN6DMBgY\nVb5CvXP8g4Cni/aOwC2Urgm4saE+ERHAQcCkYtEo4JvF3QY7A+9k5quN1CipFWtf047B/dbjgVMH\nctr+mzH+pbf4ykXjOPn6J5g+58Nqlye1KI09h6AmM+cU04cDwzLzJuCmiJjwOf3IzAURMRS4m9It\nildk5uSIOBOozcxRwIkRMQhYAMwBhhTdDwP6A6tHRF3bkOKOgmsiojsQwATg+GL5aODLwFRKdyl8\nu9HRS2oTOnWo4fgBG3HEjuvx+7HP88e/v8AdT77KkTutz9A9+7DGSis0vhGplWs0EERE+8xcAOxF\n6Xa+pvYlM0dT+qIubzujbPp0StcE1O93NXD1Z2xzz89oT0oPT5KkBq3SpQOn7b8ZQ77Ym9/e/xxX\nPfISN9RO55jdN+TY3Tdg5U4+kV1tV2OnDK4DxkbEXyjdVTAOICL6AD5MXNJyae1VOvF/B2/NPT/o\nz8BNu3Ph/c8x4JwHuOJvLzB3gc8wUNv0uYEgM38F/BC4Etgt/3XvTjvg+5UtTZIqa6PuK/G7I3fg\nLyfsymZrr8yZtz/FXueN5ebxM1i4yFsV1bY0etthZj6Smbdk5gdlbc9m5vjKliZJy8YXenXjmmN2\n4qqj+9GtSwdOueGffOXCcdz/9Os+w0BtRlOfQyBJrVpEsPvG3Rl1wm5cdMR2fDx/IUePqOWwyx7m\n8ZfmNL4BaTlnIJCkMu3aBf/xhXW495QB/PKgrXhx9occ8vuHOWZELc++/l61y5MqxkAgSQ3oUNOO\nb+y8PmNPHcip+27Ko9Nms+8FD/LDG/7JjLd8hoFan0ZvHZSktqxLx/acsEcfvt6v9AyDKx96kdv+\nOZOjdlmf+QsX0aHG31VqHQwEktQEq67YkR9/eXOGfLE3F9z3LH/8e+np7auvuAI/vXVSI71bvhfe\nLF037lhajrpxfDx/IZ061FR8fwYCSVoM63TrzNmHfoFjd9+Qwy57mLc+nMcdTy7/T0l/96P5AI6l\nBakbx/yFiwwEktRSbbzWymyy1soAjPzOLlWuZukdftnDgGNpSerGsayeoOnJL0mSZCCQJEkGAkmS\nhIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmS\nhIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmS\nhIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJFHhQBAR+0XElIiYGhGn\nNbB8SETMiogJxeeYon3biHg4IiZHxMSIOLyszzXFNidFxBUR0aFoHxgR75Rt64xKjk2SpNakfaU2\nHBE1wCXA3sAM4LGIGJWZT9VbdWRmDq3X9iHwzcx8LiLWAR6PiLsz823gGuAbxXrXAscAvy/mx2Xm\nAZUYjyRJrVkljxD0A6Zm5rTMnAdcDxzYlI6Z+WxmPldMzwTeALoX86OzAPwD6FmR6iVJakMqGQjW\nBaaXzc8o2uo7pDgtcGNE9Kq/MCL6AR2B5+u1dwCOAu4qa94lIv4ZEXdGxJYNFRURx0VEbUTUzpo1\nazGHJElS61TtiwpvA3pn5jbAvcCI8oUR0QO4Cvh2Zi6q1/d3wIOZOa6YHw+sn5lfAC4Cbm1oh5k5\nLDP7Zmbf7t27N+NQJElaflUyELwClP/i71m0fSIzZ2fm3GJ2OLBD3bKI6ArcAfwkMx8p7xcRP6N0\nCuGUsm29m5nvF9OjgQ4RsUbzDUeSpNarkoHgMWDjiNggIjoCg4FR5SsURwDqDAKeLto7ArcAf8rM\nG+v1OQbYFzii/KhBRKwdEVFM96M0ttnNPipJklqhit1lkJkLImIocDdQA1yRmZMj4kygNjNHASdG\nxCBgATAHGFJ0PwzoD6weEXVtQzJzAnAp8BLwcPH9f3NmngkcCnw3IhYAHwGDiwsPJUlSIyoWCOCT\nQ/ej67WdUTZ9OnB6A/2uBq7+jG02WHNmXgxcvDT1SpLUVlX7okJJktQCGAgkSZKBQJIkGQgkSRIG\nAkmShIFAkiRhIJAkSRgIJEkSBgJJkgREW366b9+VV87aHXZofMUmmDzzXQC2XKdrs2yvmhxLy9Ra\nxtJaxgGOpaVqLWOp1Dhi7NjHM7Nv/faKPrq4LVne/8OTJLVtbfsIQd++WVtbW+0yWpzDL3sYgJHf\n2aXKlSw9x9LytJZxgGNpqVrLWCo1joho8AiB1xBIkiQDgSRJMhBIkiQMBJIkCQOBJEnCQCBJkjAQ\nSJIkDASSJAmfVKgGLO8P8yjXmsYiSZXkEQJJkmQgkCRJBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKE\ngUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKE\ngUCSJGEgkCRJGAgkSRIGAkmShIFAkiRR4UAQEftFxJSImBoRpzWwfEhEzIqICcXnmKJ924h4OCIm\nR8TEiDi8rM8GEfFosc2REdGxaF+hmJ9aLO9dybFJktSaVCwQREQNcAmwP7AFcEREbNHAqiMzc9vi\nM7xo+xD4ZmZuCewHXBAR3YplZwHnZ2Yf4C3g6KL9aOCtov38Yj1JktQElTxC0A+YmpnTMnMecD1w\nYFM6ZuazmflcMT0TeAPoHhEB7AncWKw6AjiomD6wmKdYvlexviRJakQlA8G6wPSy+RlFW32HFKcF\nboyIXvUXRkQ/oCPwPLA68HZmLmhgm5/sr1j+TrG+JElqRLUvKrwN6J2Z2wD38q9f+ABERA/gKuDb\nmbmoOXYYEcdFRG1E1M6aNas5NilJ0nKvkoHgFaD8F3/Pou0TmTk7M+cWs8OBHeqWRURX4A7gJ5n5\nSNE8G+gWEe0b2OYn+yuWr1Ks/ymZOSwz+2Zm3+7duy/F8CRJaj0qGQgeAzYu7groCAwGRpWvUBwB\nqDMIeLpo7wjcAvwpM+uuFyAzExgDHFo0fQv4SzE9qpinWP7XYn1JktSI9o2vsmQyc0FEDAXuBmqA\nKzJzckScCdRm5ijgxIgYBCwA5gBDiu6HAf2B1SOirm1IZk4A/hu4PiJ+CTwBXF4svxy4KiKmFtsa\nXKmxSZLU2lQsEABk5mhgdL22M8qmTwdOb6Df1cDVn7HNaZTuYKjf/jHwtaUsWZKkNqnaFxVKkqQW\nwEAgSZIMBJIkyUAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIk\nDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIk\nDASSJAloX+0CJDXNyO/sUu0SmkVrGYfU2niEQJIkGQgkSZKBQJIkYSCQJEkYCCRJEgYCSZKEgUCS\nJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZJEhQNB\nROwXEVMiYmpEnNbA8iERMSsiJhSfY8qW3RURb0fE7fX6jCtbf2ZE3Fq0D4yId8qWnVHJsUmS1Jq0\nr9SGI6IGuATYG5gBPBYRozLzqXqrjszMoQ1s4hygC/Cd8sbM3L1sHzcBfylbPC4zD2iO+iVJaksq\neYSgHzA1M6dl5jzgeuDApnbOzPuB9z5reUR0BfYEbl3aQiVJausqGQjWBaaXzc8o2uo7JCImRsSN\nEdFrMbZ/EHB/Zr5b1rZLRPwzIu6MiC2XoGZJktqkal9UeBvQOzO3Ae4FRixG3yOA68rmxwPrZ+YX\ngIv4jCMHEXFcRNRGRO2sWbOWsGxJklqXSgaCV4DyX/w9i7ZPZObszJxbzA4HdmjKhiNiDUqnJO4o\n29a7mfl+MT0a6FCs9ymZOSwz+2Zm3+7duy/OeCRJarUqGQgeAzaOiA0ioiMwGBhVvkJE9CibHQQ8\n3cRtHwrcnpkfl21r7YiIYrofpbHNXor6JUlqMyp2l0FmLoiIocDdQA1wRWZOjogzgdrMHAWcGBGD\ngAXAHGBIXf+IGAdsBqwUETOAozPz7mLxYODX9XZ5KPDdiFgAfAQMzsys1PgkSWpNKhYI4JND96Pr\ntZ1RNn06cPpn9N29ofZi2cAG2i4GLl7SWiVJasuqfVGhJElqAQwEkiTJQCBJkgwEkiQJA4EkScJA\nIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJA\nIEmSMBBIkiQMBJIkCQOBJEkCIjOrXUPV9O3bN2tra6tdhiRJy0xEPJ6Zfeu3e4RAkiQZCCRJkoFA\nkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFA\nkiRhIJAkSRgIJEkSBgJJkoSBQJIkAZGZ1a6haiJiFvBSM25yDeDNZtxeNTmWlqm1jKW1jAMcS0vV\nWsZSiXGsn5nd6ze26UDQ3CKiNjP7VruO5uBYWqbWMpbWMg5wLC1VaxnLshyHpwwkSZKBQJIkGQia\n27BqF9CMHEvL1FrG0lrGAY6lpWotY1lm4/AaAkmS5BECSZJkIGgWEXFFRLwREZOqXcvSioheETEm\nIp6KiMkRcVK1a1pSEdEpIv4REf8sxvL/ql3T0oiImoh4IiJur3YtSyMiXoyIJyNiQkTUVruepRER\n3SLixoh4JiKejohdql3T4oqITYt/F3WfdyPi5GrXtaQi4gfF/94nRcR1EdGp2jUtqYg4qRjH5GXx\n78RTBs0gIvoD7wN/ysytql3P0oiIHkCPzBwfESsDjwMHZeZTVS5tsUVEACtm5vsR0QH4G3BSZj5S\n5dKWSEScAvQFumbmAdWuZ0lFxItA38xc7u8Rj4gRwLjMHB4RHYEumfl2tetaUhFRA7wC7JSZzfmM\nlmUiItal9L/zLTLzo4i4ARidmVdWt7LFFxFbAdcD/YB5wF3A8Zk5tVL79AhBM8jMB4E51a6jOWTm\nq5k5vph+D3gaWLe6VS2ZLHm/mO1QfJbLBBwRPYGvAMOrXYtKImIVoD9wOUBmzluew0BhL+D55TEM\nlGkPdI6I9kAXYGaV61lSmwOPZuaHmbkAGAscXMkdGgj0mSKiN7Ad8Gh1K1lyxWH2CcAbwL2ZubyO\n5QLgR8CiahfSDBK4JyIej4jjql3MUtgAmAX8sTiVMzwiVqx2UUtpMHBdtYtYUpn5CnAu8DLwKvBO\nZt5T3aqW2CRg94hYPSK6AF8GelVyhwYCNSgiVgJuAk7OzHerXc+SysyFmbkt0BPoVxyGW65ExAHA\nG5n5eLVraSa7Zeb2wP7ACcUpt+VRe2B74PeZuR3wAXBadUtacsUpj0HAn6tdy5KKiFWBAymFtXWA\nFSPiG9Wtaslk5tPAWcA9lE4XTAAWVnKfBgL9m+J8+03ANZl5c7XraQ7FodwxwH7VrmUJ7AoMKs69\nXw/sGRFXV7ekJVf8iiMz3wBuoXSOdHk0A5hRdtTpRkoBYXm1PzA+M1+vdiFL4UvAC5k5KzPnAzcD\nX6xyTUssMy/PzB0ysz/wFvBsJfdnINCnFBfiXQ48nZm/qXY9SyMiukdEt2K6M7A38Ex1q1p8mXl6\nZvbMzN6UDun+NTOXy189EbFicbEqxeH1fSgdGl3uZOZrwPSI2LRo2gtY7i6+LXMEy/HpgsLLwM4R\n0aX4/7K9KF0HtVyKiDWLf65H6fqBayu5v/aV3HhbERHXAQOBNSJiBvCzzLy8ulUtsV2Bo4Ani3Pv\nAD/OzNFVrGlJ9QBGFFdOtwNuyMzl+pa9VmAt4JbS/1fTHrg2M++qbklL5fvANcXh9mnAt6tczxIp\nwtnewHeqXcvSyMxHI+JGYDywAHiC5fuJhTdFxOrAfOCESl+06m2HkiTJUwaSJMlAIEmSMBBIkiQM\nBJIkCQOBJEnCQCBpGYqItSPi+oh4vnh08eiI2KTadUnyOQSSlpHiQTG3ACMyc3DR9gVKzyao6BPY\nJDXOQCBpWdkDmJ+Zl9Y1ZOY/q1iPpDKeMpC0rGwFtJYXNEmtjoFAkiQZCCQtM5OBHapdhKSGGQgk\nLSt/BVaIiOPqGiJim4jYvYo1SSoYCCQtE1l6k9pXgS8Vtx1OBv4PeK26lUkC33YoSZLwCIEkScJA\nIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAn4/1X4515haSB/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYfRZ4zmKYaq",
        "colab_type": "code",
        "outputId": "169fd823-b324-4384-a059-c6117275ca93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, Y = make_blobs(n_samples=300, centers=10,\n",
        "                  random_state=0, cluster_std=1.0)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap='rainbow');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG+3+QSE/OVv2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7QaJcE4Kkwm",
        "colab_type": "code",
        "outputId": "e1f1dcd7-1ecd-404a-eff7-f25aaa0c0ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
        "    ax = ax or plt.gca()\n",
        "    \n",
        "    # Plot the training points\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
        "               clim=(y.min(), y.max()), zorder=3)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "    \n",
        "    # fit the estimator\n",
        "    model.fit(X, y)\n",
        "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
        "                         np.linspace(*ylim, num=200))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "    # Create a color plot with the results\n",
        "    n_classes = len(np.unique(y))\n",
        "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
        "                           levels=np.arange(n_classes + 1) - 0.5,\n",
        "                           cmap=cmap, clim=(y.min(), y.max()),\n",
        "                           zorder=1)\n",
        "\n",
        "    ax.set(xlim=xlim, ylim=ylim)\n",
        "\n",
        "visualize_classifier(rf, train_features, train_labels);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-17500496683b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mvisualize_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-17500496683b>\u001b[0m in \u001b[0;36mvisualize_classifier\u001b[0;34m(model, X, y, ax, cmap)\u001b[0m\n\u001b[1;32m     14\u001b[0m     xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n\u001b[1;32m     15\u001b[0m                          np.linspace(*ylim, num=200))\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Create a color plot with the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 138 and input n_features is 2 "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAczUlEQVR4nO3dd3hc1Z3/8feZ0aiOe7flhtzABQzY\ngE0znWBYEVj6AmHDj2eom82PkIVdsqEGQqghs9lNpbewApuytBgMwRRjY7DBHTfZ4CKXUZ+Zs39c\nCauMWRufe0cjPq/n0QO5yuPv4Vr6zLmnXWOtRUREghHKdgNERL5LFLoiIgFS6IqIBEihKyISIIWu\niEiAFLoiIgFS6IqIBEihKyISIIWuiEiAFLoiIgFS6IqIBEihKyISIPeha8y5GLMaY1IY8ynGHOW8\nhohIjjJOTxkz5mTgGaC4xdUa4ECsXeyukIhIbnLd072B1oELkA9c4biOiEhOch26/TJcywNKHdcR\nEclJrkP3eaChzbVqoMJxHRGRnOR6TLcHMAcYABQBdU3/+3tY2+iukIhIbnIbugDGRIBTgVHAB8Ab\n6J1AIiKAH6ErIiK7pM0RIiIBUuiKiARIoSsiEiCFrohIgBS6IiIBUuiKiARIoSsiEiCFrohIgBS6\nIiIBUuiKiARIoSsiEiCFrohIgBS6IiIBynP+JxpTApwLjAHeAyp0lq6IiMf1Ieb9gLlAd6AESACL\ngKOwts5dIRGR3OR6eOFGoC9e4AJEgbHAPziuIyKSk1yH7olApM21EuAUx3VERHKS69BdneFaA7Dc\ncR0RkZzkekz3aOAFoLjF1QQwAWtXuiskIpKb3PZ0rZ0FnAkswAvb2XiTaApcERH0YkoRkUBpc4SI\nSIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKEr\nIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLo\niogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAU\nuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIg\nha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogE\nSKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIi\nAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogEKC/bDZCOY2A8\nMQK4ACgGnqmMRd/PcpNEOh1jrc12G6QDGBhPnAo8AUSAMFAH3F4Zi96S1YaJdDIKXWFgPBEGNgC9\n23yrHhheGYuuD75VIp2TxnQFYDDekEJb9cChAbdFpFNT6ArAZjL/LISBNQG3RaRTU+gKlbHoDuAP\nQE2Ly/XAQmBuVhol0kkpdKXZ1cAtwDpgE/B74PjKWFSD/iIOaSJNRCRA6umK+MWYQRhThjEm202R\njkOhK+KaMX0w5i1gGbAAWIYx+2e5VdJBaHhBxDVj3gAOx9toAmDxVogMwtqGrLVLOgT1dEVcMqY3\nMIWdgQtggHxgWlbaJB2KQlfErW86zyQ/sFZIh6XQFXHJ2g3A50C6zXdCwBvBN0g6GoWuiHtnAmuB\nHcC2pn+ejrXVWW2VdAiaSBPxgzEh4DC8My3extraLLdIOgiFrohIgDS8ICISIIWuiEiAFLoiIgFS\n6IqIBEihKyISIIWuiEiAFLoiIgFS6IqIBEihKyISIIWuiOwZY47DmHkYsx1jZmPMpGw3KZdoG7CI\n7D5jpgKv4J0p0awamIi1S7PTqNyinq6I7IkbgKI21wqAa7LQlpyk0BWRPTEM700YLeUBZcE3JTcp\ndEVkT7wMtH3PWw3wYhbakpM0pisiu897B9xcoBdQAiTw3no8FWtrstm0XKHQFZE9Y0wJcA4wFngf\neFZvOd59Cl0RkQBpTFdEJEAKXRGRACl0RUQCpNAVEQmQQldEJEAKXRGRAOVluwG55rTEvP2B44Cv\ngGefj06sznKTRCSHaJ3uHjgtMe8uIIb3YVXf9DXl+ehEna4kIrtFwwu76bTEvIl4gVsM5ANdgJ7A\nf2azXSKSWzS8sPuOByJtroWAI7LQFhHxQ7w8ApwPnAGsBx4gVvGJyxLq6e6+jXjDCW1tD7ohIuKD\neLkBZgK/BqYDlwBziJef4LKMQnf3PQM0Ai0HwauBu7LTHBFx7EhgCt7paQBhvOHEB10WUejupuej\nE3fg/YW8A6SBrcAvmr46h3h5CfHys4mXX0y8vG+2myMSsIPw5mvaGkG83FlWavXCt3BaYp55Pjqx\nc924ePnBwKt4n+6m6Z+XEKt4IqvtEglKvPwU4HG8SfKW1hOrGOiqjHq630InDFwDPAV0x/uBi+K9\nB+sPxMu7ZbNpIgF6GfgCqGtxrQb4icsiCl0BGAz0z3C9ETgq4LaIZEesIgUcDvwK+Bx4CziTWMUj\nLstoyZiA98qVTB/ABtgWcFtEsidWsR3416YvX6inKxCr2IL3aNXysSoFbAZmZ6VNIp2UQleaXQBU\n4L3pNQn8DTiaWEU6q60S6WS0ekFai5fnA3nEKvRmVxEf5H7oeutJzwQKgeeIVSzPcotERHYpt0M3\nXj4NmMHOdaUWuIZYhQ6hEZEOKXdD19shso72S53qgFJiFZuDb5SIyDfL5Ym0oUDXDNcbgKkBt0VE\nZLfkcuhuxRtSaCuE91YHEZEOJ3dDN1ZRBTwL1La42gisAt7LSptERP4PuRu6nkuA3+HtqGoAngem\nEavI0YHqLDImhDH/jDErMaYSY+7GmGi2m5WTvHv5I4xZgTHrMeYejGl7iIp8R+XuRJq4Zcx9wA/x\nzg8F78D2ucDh6IdkzxhzN3AZre/lPGCK7qUodIWmHu1GvLXOLVUDR2LtR8E3KkcZU4J3L4vafKca\nOBprPwy+UdKR5PrwgrjRG+9g9rZSeKtEZPf1ovXbRZrpXgqg0BXPWlofdtOsAHg/4LbkunV4Z7C2\nlY/upaDQ7fAGxhNlA+OJkwbGEwN8K2JtEm88twbvsJt007/fibXrfKvbGVmbwruXtex8p141cDfW\nrslm06Rj0JhuBzUwnogAjwGn4K3MKATuB66rjEX9+UszZgxwEd6L+Z7C2rd9qfNdYMxo4GK8e/k0\n1uqITAH8CF1jQsCxwCjgA+ADzdjuuYHxxD8DN7NzBhy8HtPZlbHoC9lplYjsLbdvjvDWIr4FlDX9\n2WngFYz5+6bHLtl9P6B14ILXa7oQ8Cd0jekP/D3ezPtzWLvYlzqdXNNTyk14y8YKgOeAqytj0U1Z\nbZh0CK7HdP8FGIP3csMivJA4Hu8XWfZMY4ZrFm+owT1jjgGWAXfg9bDnYcwVvtTq/OLA1UAPvA/O\nM4G/DownTFZbJR2C69BtPte2pSgK3W/j13jDCS3VAu6PrfSGhB7F+5AswptpLwLuwpg+zut1YgPj\niS7A+bR+SokAw4DDstEm6Vhch26m4xST6ACab+OPwH/gLeXagRfA11bGon5MyAxGJ7a50oPM63TT\nZH7jsnzHuA7dO2m/RrEBeNBxnU6vMha1lbHo/8f7RT0M6FMZi/7Gp3LfdGLblz7V7KzWAlUZrucD\n7wTcFumA/Fi98P+A24DueD+AMax9yW2Rr2sZ4B/xxs8KgYfx1pbW+1KvMzPmIbzhoebtq43AEmC8\nVp/smYHxxLF4hy+F8CaUG4EbKmPRe7LaMOkQ/AjdMHAcsB/wLvCeb7+0xvwCuBJvLBK8Mc+3sPYk\nX+p1ZsbkA7fjLexvnnG/Ams14/4tNG1mORtvbPe5ylh0YZabJB2E29D1loy9DQzHmzxIAa8BZzhf\nMrbrg0VqgEOw9lOn9SS3xcvLgbvwxq8/A64kVqHNHxI416F7O/AjvJ5SswRwKdY+4a4QYEwZ8DE7\ne7nNtgEXY22F03qSu+LlzY/7LVcU1AAHEav4PDuNymHx8uYVGuPwXhjwFLEKDentJtcTaWfQOnDB\nvyVja/BWRrRVgHcOrHwbxgzCmLKm8fLO4nrabzTJB67KQltyW7y8L96Twl3AFcBvgA+Il7ft/Mgu\nBLVkzP0MuLUNeBNoNew8lrAaiOtgkW/BmL4Y8zbeBokFwFKMGZ/lVrkyKMO1PGCIbxWNMRgzFmMm\nYYzbnZ/ZdT3Qh51PmFG8Hag/zFqLcozr0L2DzEvG/FnqZO1DwFF4r+x5FK9H/WNfanV+TwOT8VaB\nFAP7AK9jTMS3isZ0x5jvYczBPvesZ+C9vaGlarwhB/eMKQU+wXv0fh2oxJjOsjHiBLynhJaKAU1e\n7ya3oeuNo/4TsAmv97kSbxLNv0ktaz/E2suw9gKsfUnLm74FY/oCh+BNfn59FW+o5mifal4EVOKd\npDYLmI8xvX2p5S1hXIO3ycTizTPMBx7yqd4zwGi83mAXvJ7hSxjTdrdmLlpJ+80fjXhPSLIb3D/2\nWPtfGPM7IF/rZXNGHpl3UUH7Xs3eM2Yo3m67QnauPtm36dqZzuvFKqooyb8KYx6kPhmhKG8FDalr\nqEu6//n0PsAOoP3vlgGOAV50XjNYN+N9ELccI68H7s1Ka3KQP4eYW2sVuDnE2kq8nkrbV/aEgL/6\nULE8w7UIcJovwwzGTKWm8S9UN+xDMl3IjoYJ1KdmYcw+zmt1drGKOcB0vGNbq/B+Po4kVrE8q+3K\nIX5sjhgM/AoYC8wGrsXaHW6LiHPGjMQbf+ze4urpWPu6D7VieLPfbVcU1GJt22su6r0MnNjmaiPw\nINb+yId67wKTaL21eiswAGszvRZJvkNcn6c7EfiQnT3o/YALMWYQ1mbajy4dx0a8VQvN4fQpsNqn\nWs8Av2xzrR7/xliHZ7gWwTto3w9nAi831U3jHVp0mq+B6+0EHQVswVrfz8v4uaEr3kaTlT+zGd8J\nl5NmJuJh4CzgdGA9EJ8ejTldy+16c8QivLG5th7D2vPdFfpumJmID8NbjbE/3uHw906PxvzZlmvM\nG3hjdS0f778CBvqwm9AAc/B6g831UsDJWPuq01pevQfwDhRvOVFYA1yHtb92Xs+reSze+dJRvNU7\nj2Btpjcuu6r1GN6TQx7wCnAe1rY9GnSv/dxgig/86sHS8z68tM+oVaZy/uj0+sf3/9l1i3rd7rpW\n0GYm4gZv+/sxeJOgSbzVV6dOj8becFXHdegmyXxa1Sas1bmse2BmIj6qy8J1c0fe8VJx9PP1oapD\n9kktu/akjbVDeo2dHo1tcVrMmN4WvjKtAxcL1sCJzoPQmKPxlnFF23xnIdaOc1rLq9cfWE7r4YwN\nQBnWuu+lecMn97Bzo1AD8IwvHQ/vvOOVtN6ZWQc8irXO187ed8rya//u8nvvHLx2HelwiFAqzZJh\nI+2Lt1x9+o9nD3rOdb0gzUzED8d7Qmm70WPJ9GhstKs6Qb0N2LdlXDMT8aKZifjpMxPxc2cm4j38\nqhO0nrOX3DP16DuiA/77o1DXz9Yz5M/vhI847Nb+XRZV+rEOeRBtAreJAQ71od5k2u9cBNjPp/W6\n3wdgWA84ZDAM6ALeUq4jnFfyDg66l9b/ffnAORjjx3DG92n/d1cIXODHvTzszGdvLF23jnA6TaQx\nSTidZuSqZWbi2S92htULk2j9NNRs1MxE3FlWug7djbu4Pt9xHQBmJuITgXXAn4DfAutmJuKZZsZz\nzph/r5gWrkt+/dtkLES211F218vnuK710dCDdjnR+e4BR/mxCmUlmecTtvmyzjo/fNlbP728+IaT\nb+G20ku54exfsuDys0owXOK8lveGiEzL7EJkXrWxd8KhQvJCbQ99AuPDclBgVPjTkrxU61GSvFSK\n0d3mD/CjXsCW0X4TDcCX06MxZ0NDrv9iPiHz6fhzHNdpHn/5C95J/S09NjMR7zc9GnO+YmLx9dNN\nsnvRZXX9u58Vrm3YULiu6voxNz3/hes6AN3mr8lv200xQJ/XFnXP9P/fGw8+/EDfe39QTnT5V626\nTKnCCDN++aOePmylyidzzzpT73evvX/G6SP6PDyLn256iEiqkVQ4jw/LJrP0xCMnjXRfrtc3fM99\nucsmV/Mf77W/lyN7JVm8yfkHmEnaWtqvOiGSSu6qw7VXZibi+XibWy7F+/l4Abh8ejTmx2ThS3hn\ngO/Dzp/FGryxeWdc93SH7eJ6psm1vTUEGFpFIe8xmHcYygZviLAQb2uwc1sPGLIwf8P2+IibXpg2\n6E/vnrv50LIVi249w5eedagxnbGHGdle63Y8F5g4eM3qOU9fSd2g7qQKI6SKIjRGC3jn8avoNsT6\ncQ7s93aRBkV+PBKv21hYPPzL5XSpT1CYrKekvpqDl73Hx8X7lrquRSS0gpAhbQzbenZjc9+epENN\n/0l9Sz52Xi+VHk2mh4OGVAHxcuf3Ml1g7kiGW8dGMhwmv6D2Wte1msSBy/FeJ1UAnAa86fJxv9n0\naCwJTMHaB00ytYpk+kPgvOnR2B9d1nHacOsdq9j2WprMry/ZW5EV9Aw9y3gWMICF9OdF9mUugwze\nG4mdWnjL9y8af/kT+4645xW6LV9P7zlLmXLKvcZsa3jMdS0ArN3Q9lfJAqGU+xC8cthZlRsTY6pf\nnX8rc2ZczftPxXhlxZ1sOWCcLV2Y96TreukMPaWm676YuOBvFLbZfFbSUMPwRR9nmvTdO7edmF/V\nrxcv3HAh2w8eSsO+/Zj147NYNWoYnDXB/ZKxl5ZErYVUKMTq0cOp6tvU0f5iK1zufl6rx/Ztt1T2\n6ftZ0oSoz4vQGAqzZkD/N7qf+5Dbo1uBmYl4FDh/02Ojij7d92wWDLuAtT+blJdOMRCf3t03bey/\njS99ZM4P8zbWDSlevPGg8Vc9erXr7dtOhxfWnHPI6sFPvHdwm4/X0PIrps0vc1kIqCc8eDbDSbVY\nLJEkzHw7iGGmarDjcpTM3nhD0eYqkhSxngMp4St6sZQRd79WxJ2uq0FNXuHg4mT739Ht+dFJmd4g\nuTd+buhRNPrIktGvP0+yuICQCZEmzLqrJ5vtM4ZOxbrdlbY52nu/3on2K9/8OvHGRtr3LZIYoqka\n54/fNf+9uM+yUw7m5F89RqguScha+nywnLVH78eGFXWn9vcOZ3LGrt464KPjD+Ouh+6goaiANIZx\n78/j+vJrKKqudf7fd98J513Xr/uOfbs0VtOttpotJV2pSkePeXn14+WxIee6PsO626qLp0Q2/WVC\n0/80fHn3QWx9bHh03NKnnL/ks6a0R/dZs298M9270BgDDf1LWHD/+cdsGV/214kO3+TsNHSTKwpP\na3vNGkNi24AbcXzS2DsMS6RTtFugltfYwJL83s47Tfnv1gxayJk8h/ekYQkzkA85NzU943Tn3ipM\n1UcyjemGbcr5hMWEYX8aGb6+jmOO+DeKV2/BAqloAXN+/09s2TDyfPiB09CtKuxdmil0MfC3EYcz\nxWUxoE/+jq+Xzxi8J4YwliHhr5z3dD+ZsG/soIdfI6+2Ebp6w4J51fUMefUTZl1efpLrpFh0yLiR\ntz11L415O38KF046gPsev52fGmNcT0wm6gtu6dpQS2QeMKCA2k/BHmxZv6XLYwzJ/ATzbS0758Sq\nbS8MDdkQJKYkSBenib4dpWFDd7P6gimDcBzx82686D+T0WJjGiDdGMbkpUnXh1j7g0MPnejwXjod\nXiidNyevbVCErGXQa+/0dVkH4MAFK/ul0+37RkkTZszzC/dzXW9ZzfF5z/IISaIkiZKiiDVMZQb/\n5brUNwqnGp13CPvdN2+/Y6/7F0pWbiKUShNOpcnfVsvUc+6g9yWfTPi//4Q9UzdixC4e1wxTlrp/\ng07h+qqmP51W/4ysdz/q1ePLLw8NN3dlttd7XykwJRH6btnmfEXBvPOOHx2qb32WfzIvwvtHTOE3\n8X91XY6CNV+F+pkqCqaGsSOLKDnc0i9ZRV4y0X4FxV7qsrLywsayBJ8sWsiyJ1ew4o9fsGD5p+w4\nfiPM4ieu6208cPSxxhhCBWnC0UZChSlChSnq1hbz+lM3OfuAdhq6eY3t534sEN28wXlQjH/wqX9M\nG0PbSYRUXh7jX/ufaa7rrTWTI7bdSqAQnzUtAXVta9ee7RY3W2BTP+cjJ2z5/YhuxRu2tnu8DyXT\nFD+zfKzrekMSCzL/PFjLovN9mJdMp9v9txmgMe3+ALWa6iGGbRnmQLfW0StR67xeeHsyZEPtb6fF\n0FjW03m9g75aSbooAs2TaZEw6aIwh73u/vTWgZvemrr04bU09m8k3TXtfUXTLH14A30K33TekUsu\no4dt05ELFaQpKK1lPQc5q+M0dHe1uj6SbHBZBoBN0ZLv2XAIMkx2fzjhIOePjSa5qz/S/VwMQJcd\n2zIGRVFiu/Naw+b97he7+t7gj991fgZs/vp2861f22fGa67LETaZnwojeW53NwN0i1SO2NX3uq5w\nf5TFlIfan0cUrm9g0otvcukJNzmvx375OwO3iS2MUDza/QdK3ag1JzWMqm33KxZKpdh0dq3z1Qs7\nNvXIvI3LGobf++/HuKrj+440CyQj7tdp56/btst95XnV7ieJB+zitWuhjK9p23vpcPt7ZoFknvul\nrA1RdnnD6orc16vN3/XQX+G2Hc4nf2zX9k++Fmjs2c11KRpJNu7qe3UR9z3ryCq48oqbKKippXjb\nDgoTNQz9bAVXXHMrS7oe57xetw9WQ7L1h1WotoEu765zXiuct2WJof0HY4RaMI3Of07Cc7/wdiG1\nkK4PsfnVoSw94VBnW+Gdhu7q0sEZR5oXjRjnvEtxxMw3exZvT7QeXrAWk7ZMevLF81zXG9j15dpw\nu80qKfbnD65LAbB42KSM93Lx4MnO7+WBiz7ukTam1Yd8878vGTDc+f79HT2K2n1gWiDRxX0IAnxW\ndqhtt4IhEmLuwMOd38tRMz/oQijzvazs1+e3rut9XjpmyVFPv8yfy47nun/4Cb844RLuPuI8Grf0\n5IBtTzsPpvr70zYvUY+p9z5bQrUNRLZUs3pmqfN7edpfn5zaY1UV4YYWT8rpNNbAkI/mXeS63gGL\nHkksuv1wklvzSW2PkK4Nk/igH1ve38TFP7vf3b30zht387WlRw+ztVtXm4avv74oHZJ2WaPl17vH\nHvrV2WvftKdun2tP3T7Xnr5pjp1xYXmDX/U+DZenfkmlvYUaezN19mket5/1GPusH7WWDxprVgwc\nk255LxeUHebbvfxw7P6bk6FQq7+7JWVljX7VWzZi31TLWtuLu9gvxpe97ketDQdMMF/uPy6djoRs\nOj9s0wV5dvGkI327l0tPmbQjHTKt7uWqYyb4di9nl56bbKDg61obzGg7a+TpD/hR64vwZLOk9Kj0\nwpvL7bvPXWU/v+5k+1G/v/PtXs445py3zv9sli3f8r49fdMce9aa2fbxs6+s86verPITk1fe9rH9\n2Q+X2Z9cucLecuuf7fyJY5a7rOH+EHPgzQOnvlOQTh1cZ8L3Hz3vHb92qnztbydM3dJQXFT04uXn\nFd95wiW+viNtac9x+9mGXvPIS1SN2jrX+VrBth495IoXeiWrjtuQ1+vei9974Dq/680fO2FHJJmM\nDNmwpqiLD4/6La0dXzauMRWZa8KpxLBPln7T9lkn3jjx+1+a+vzuFDTOn/Y/fznE73rLTplcHbbp\ncOl7nxdFNid8vZevjz53kLH5S4ypXzFt8RO+v8X5t2fcPLtglZncWNbwp0ufvOkyv+vNOO78hemC\n/L4vX3le3/jJx/t6L+cdOPKoUPdur4Rr6urHzfnU9bJ4f0JXREQyC+poRxERQaErIhIoha6ISIAU\nuiIiAVLoiogESKErIhIgha6ISIAUuiIiAVLoiogESKErIhIgha6ISIAUuiIiAfpfos+DbW5G7/8A\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LmzmCgJLT24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = rf.predict(test_features)\n",
        "mat = confusion_matrix(test_labels, predictions)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train_labels,\n",
        "            yticklabels=train_labels)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAm3TwsQLYUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions = rf.predict(test_features)\n",
        "triggers = [1,2,3,4,5,6,7,8,9,10]\n",
        "print(classification_report(test_labels, predictions,\n",
        "                            triggers))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}